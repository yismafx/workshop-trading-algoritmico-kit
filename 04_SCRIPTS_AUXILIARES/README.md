# ğŸ SCRIPTS AUXILIARES - VersiÃ³n PÃºblica

> **Workshop:** Trading AlgorÃ­tmico Aumentado con IA Generativa  
> **VersiÃ³n:** 1.0 (PÃºblico)  
> **Ãšltima actualizaciÃ³n:** 20 de noviembre de 2025

---

## ğŸ¯ Â¿QuÃ© es esto?

ColecciÃ³n de **scripts Python reutilizables** para tareas comunes en trading algorÃ­tmico.

**FilosofÃ­a:** No reinventes la rueda. Usa cÃ³digo probado y adÃ¡ptalo.

---

## ğŸ“‚ Contenido Disponible (1 Script PÃºblico)

### âœ… data_pipeline_simple.py

**Â¿Para quÃ©?**  
Descargar, limpiar y validar datos histÃ³ricos de mercado.

**CaracterÃ­sticas:**
- ğŸ“¥ Descarga datos de acciones/ETFs/criptos (yfinance)
- ğŸ§¹ Limpia datos (elimina NaN, duplicados, outliers)
- âœ… Valida calidad de datos
- ğŸ’¾ Guarda en CSV para reutilizaciÃ³n
- ğŸ›¡ï¸ Maneja errores comunes

**Compatible con:**
- Acciones/ETFs: SPY, AAPL, MSFT, etc.
- Criptos: BTC-USD, ETH-USD, etc.
- Forex: EURUSD=X, GBPUSD=X, etc.

**Timeframes soportados:**
- Intraday: 1m, 5m, 15m, 30m, 1h
- Daily+: 1d, 1wk, 1mo

**InstalaciÃ³n:**
```bash
pip install yfinance pandas numpy
```

**Uso bÃ¡sico:**
```bash
python data_pipeline_simple.py
```

**PersonalizaciÃ³n:**
```python
# Editar clase DataConfig en el script
class DataConfig:
    TICKERS = ['AAPL', 'MSFT', 'GOOGL']  # Tus activos
    START_DATE = '2023-01-01'
    END_DATE = '2024-01-01'
    INTERVAL = '1h'  # Cambiar timeframe
```

---

## ğŸ”§ Funciones Principales del Script

### 1. download_data()

Descarga datos usando yfinance.

```python
df = download_data(
    ticker='SPY',
    start_date='2020-01-01',
    end_date='2024-01-01',
    interval='1d'
)
```

**Output:** DataFrame con columnas OHLCV

---

### 2. clean_data()

Limpia datos eliminando problemas comunes.

**Limpieza automÃ¡tica:**
- âœ… Elimina filas duplicadas
- âœ… Forward fill para gaps pequeÃ±os (max 2 dÃ­as)
- âœ… Elimina filas con precio = 0 (datos corruptos)
- âœ… Valida lÃ³gica OHLC (High >= Low, etc.)
- âœ… Elimina NaN persistentes

```python
df_clean = clean_data(df, ticker='SPY')
```

---

### 3. validate_data()

Valida calidad de datos y genera reporte.

**Validaciones:**
- âœ… Cantidad mÃ­nima de datos (default: 100 registros)
- âœ… Porcentaje de NaN aceptable (default: <5%)
- âœ… Detecta gaps grandes en fechas
- âœ… Identifica volatilidad extrema (>50% cambio/dÃ­a)

```python
report = validate_data(df_clean, ticker='SPY')
# report['is_valid'] = True/False
```

---

### 4. run_pipeline()

Ejecuta pipeline completo para mÃºltiples tickers.

```python
results = run_pipeline(
    tickers=['SPY', 'QQQ', 'TLT'],
    start_date='2020-01-01',
    end_date='2024-01-01'
)

# Acceder a datos de un ticker
spy_data = results['SPY']['data']
```

---

## ğŸš€ Casos de Uso

### Caso 1: Descargar Datos para Backtest

```python
# En tu script de backtesting
from data_pipeline_simple import download_data, clean_data

# Descargar y limpiar
df = download_data('SPY', '2015-01-01', '2024-01-01')
df = clean_data(df, 'SPY')

# Usar en backtest
# ... tu cÃ³digo de estrategia aquÃ­ ...
```

---

### Caso 2: Actualizar Dataset Diariamente

```python
# Script cron que ejecutas cada dÃ­a
import schedule
import time
from data_pipeline_simple import run_pipeline
from datetime import datetime, timedelta

def daily_update():
    # Descargar Ãºltimo dÃ­a
    today = datetime.now().strftime('%Y-%m-%d')
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    results = run_pipeline(
        tickers=['SPY', 'QQQ'],
        start_date=yesterday,
        end_date=today
    )
    print(f"âœ… Actualizado {today}")

# Ejecutar diariamente a las 5 PM
schedule.every().day.at("17:00").do(daily_update)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

### Caso 3: Validar Datos Antes de Backtest

```python
from data_pipeline_simple import validate_data

# Cargar CSV existente
df = pd.read_csv('./data/SPY_20241120.csv')

# Validar calidad
report = validate_data(df, 'SPY', min_points=252)

if not report['is_valid']:
    print("âš ï¸ Datos no vÃ¡lidos:")
    for error in report['errors']:
        print(f"   - {error}")
    # No ejecutar backtest
else:
    print("âœ… Datos validados, proceder con backtest")
    # Ejecutar backtest...
```

---

## ğŸ”’ Scripts Premium (No Incluidos)

En el **workshop completo** recibes:

### 1. data_pipeline_advanced.py

**Features adicionales:**
- ğŸ”„ Caching inteligente (no re-descargar datos)
- âš¡ Multi-threading (descargar 10+ tickers en paralelo)
- ğŸ”€ IntegraciÃ³n multi-fuente (yfinance + Alpaca + Polygon)
- ğŸ“Š Auto-detecciÃ³n de splits/dividendos
- ğŸ’¾ Soporte para bases de datos (SQLite, PostgreSQL)
- ğŸ”§ NormalizaciÃ³n automÃ¡tica entre fuentes

### 2. backtest_analyzer.py

**Features:**
- ğŸ“Š Calcular 20+ mÃ©tricas automÃ¡ticamente
- ğŸ“ˆ Generar equity curve, drawdown chart
- ğŸ¯ Comparar con benchmark (SPY, QQQ, etc.)
- ğŸ“‰ Analizar por rÃ©gimen de mercado (alcista/bajista)
- ğŸ“ Exportar report PDF automÃ¡tico

### 3. risk_calculator.py

**Features:**
- ğŸ’° Position sizing (Kelly, Fixed Fractional, Volatility-based)
- ğŸ›‘ Stop-loss dinÃ¡mico (ATR-based, % de capital)
- ğŸ“Š DiversificaciÃ³n de portfolio (correlaciones)
- âš ï¸ Circuit breakers (detener bot si drawdown >X%)
- ğŸ’¸ CÃ¡lculo de slippage esperado

### 4. order_manager.py

**Features:**
- ğŸ“¤ Enviar Ã³rdenes a mÃºltiples brokers (Alpaca, IB)
- ğŸ”„ Retry logic si orden falla
- ğŸ“ Logging detallado de cada operaciÃ³n
- âš¡ ValidaciÃ³n pre-orden (fondos, liquidez, horario)
- ğŸ“Š Tracking de posiciones abiertas

### 5. webhook_handler.py

**Features:**
- ğŸ”— Recibir seÃ±ales de TradingView
- ğŸš€ Ejecutar Ã³rdenes automÃ¡ticamente
- ğŸ” ValidaciÃ³n de autenticidad (signatures)
- ğŸ“ Log de seÃ±ales recibidas
- âš ï¸ Rate limiting (evitar spam)

### 6. monitoring_dashboard.py

**Features:**
- ğŸ“Š Dashboard web en tiempo real (Flask/Dash)
- ğŸ“ˆ GrÃ¡ficos de performance live
- ğŸ”” Alertas configurables (Email, Telegram, SMS)
- ğŸ’° Estado de cuenta en tiempo real
- ğŸ“‹ Historial de trades

---

## ğŸ“– CÃ³mo Adaptar Los Scripts

### MÃ©todo 1: Modificar Directamente

```python
# Copiar script
cp data_pipeline_simple.py my_data_pipeline.py

# Editar funciones segÃºn necesidad
# - Agregar nuevos validadores
# - Cambiar fuente de datos
# - Personalizar limpieza
```

### MÃ©todo 2: Importar y Extender

```python
# En tu propio script
from data_pipeline_simple import download_data, clean_data

# Agregar tu propia lÃ³gica
def my_custom_clean(df):
    df = clean_data(df, 'SPY')  # Usar funciÃ³n base
    
    # Tu limpieza adicional
    df['custom_indicator'] = ...
    df = df[df['volume'] > 1000000]  # Filtrar volumen bajo
    
    return df
```

### MÃ©todo 3: Usar con Prompts de GenAI

```python
# Usar Prompt 02 (Adaptar CÃ³digo Existente)

"""
ğŸ­ ROL: Desarrollador Python senior

ğŸ“Š CONTEXTO:
Tengo el script data_pipeline_simple.py del workshop.
Funciona con yfinance pero quiero usar Alpaca API.

ğŸ¯ TAREA:
Adapta la funciÃ³n download_data() para usar Alpaca API
en lugar de yfinance, manteniendo la misma estructura.
"""

# Pegar en Claude/ChatGPT â†’ Recibir cÃ³digo adaptado
```

---

## ğŸ“ Mejores PrÃ¡cticas

### âœ… DO (Haz esto):

1. **Valida datos SIEMPRE antes de backtest**
   ```python
   # Nunca asumas que datos estÃ¡n limpios
   df = download_data(...)
   df = clean_data(...)
   report = validate_data(...)
   
   if report['is_valid']:
       # Proceder con backtest
   ```

2. **Guarda datasets intermedios**
   ```python
   # Evita re-descargar mismo dataset
   df.to_csv(f'./data/{ticker}_{date}.csv')
   ```

3. **Usa try/except para manejar errores**
   ```python
   try:
       df = download_data('INVALID_TICKER', ...)
   except ValueError as e:
       print(f"Error: {e}")
       # Usar datos por defecto o continuar con otro ticker
   ```

4. **Loguea operaciones importantes**
   ```python
   import logging
   logging.basicConfig(level=logging.INFO)
   
   logging.info(f"Descargados {len(df)} registros de {ticker}")
   ```

### âŒ DON'T (Evita esto):

1. **No asumas que yfinance siempre funciona**
   ```python
   # âŒ MALO: Sin manejo de error
   df = yf.download('SPY')
   df['SMA'] = df['Close'].rolling(20).mean()
   
   # âœ… BUENO: Con validaciÃ³n
   df = yf.download('SPY')
   if df.empty:
       raise ValueError("No se descargaron datos")
   ```

2. **No ignores advertencias del validador**
   ```python
   # Si el script dice "Detectados 5 gaps >10 dÃ­as"
   # NO lo ignores. Investiga quÃ© pasÃ³ esos dÃ­as.
   ```

3. **No mezcles timeframes sin normalizar**
   ```python
   # âŒ MALO: Mezclar 1d y 1h sin ajustar
   df_daily = download_data('SPY', interval='1d')
   df_hourly = download_data('SPY', interval='1h')
   df_combined = pd.concat([df_daily, df_hourly])  # Â¡Ãndices incompatibles!
   ```

4. **No uses datos sin ajustar por splits**
   ```python
   # yfinance con auto_adjust=True ya lo hace
   # Pero si usas otra fuente, valida que estÃ© ajustado
   ```

---

## ğŸ“Š Ejemplo de Flujo Completo

### Semana 1: Setup de Datos

```python
# DÃ­a 1: Descargar datos histÃ³ricos
from data_pipeline_simple import run_pipeline

results = run_pipeline(
    tickers=['SPY', 'QQQ', 'TLT', 'GLD'],
    start_date='2015-01-01',
    end_date='2024-01-01'
)

# Validar que todos descargaron bien
for ticker, result in results.items():
    if result['status'] != 'success':
        print(f"âš ï¸ {ticker} fallÃ³: {result.get('error')}")
```

### Semana 2: Desarrollo de Estrategia

```python
# DÃ­a 2-5: Usar datos para backtest
import pandas as pd

# Cargar dataset guardado
spy = pd.read_csv('./data/SPY_20241120.csv', index_col=0, parse_dates=True)

# Implementar estrategia
spy['SMA_20'] = spy['close'].rolling(20).mean()
spy['SMA_50'] = spy['close'].rolling(50).mean()
spy['Signal'] = (spy['SMA_20'] > spy['SMA_50']).astype(int)

# Calcular retornos
spy['Returns'] = spy['close'].pct_change()
spy['Strategy_Returns'] = spy['Returns'] * spy['Signal'].shift(1)

# MÃ©tricas
total_return = (1 + spy['Strategy_Returns']).prod() - 1
sharpe = spy['Strategy_Returns'].mean() / spy['Strategy_Returns'].std() * (252**0.5)

print(f"Total Return: {total_return:.2%}")
print(f"Sharpe Ratio: {sharpe:.2f}")
```

---

## ğŸ”— IntegraciÃ³n con Otros Recursos

### Con Templates:

```
Paso 1: data_pipeline_simple.py â†’ Descargar datos
        â†“
Paso 2: Documentar en Strategy_Memo_Template.md
        SecciÃ³n: "Datos utilizados" (fuente, periodo, limpieza)
```

### Con Prompts:

```
Paso 1: Ejecutar data_pipeline_simple.py
        â†“
Paso 2: Si hay error â†’ Prompt 04 (Debugging)
        â†“
Paso 3: Adaptar script â†’ Prompt 02 (Adaptar CÃ³digo)
```

---

## ğŸ’¬ Soporte

**Â¿Script no funciona o necesitas ayuda?**

ğŸ“§ Email: yismaryme@gmail.com (adjunta traceback completo)  
ğŸ’¬ Telegram: [@yismafx](https://t.me/yismafx)  
ğŸ”’ Grupo Premium: [Code reviews + scripts avanzados]

**Errores comunes:**

- "ModuleNotFoundError: No module named 'yfinance'"  
  â†’ SoluciÃ³n: `pip install yfinance`

- "ValueError: No data found for ticker"  
  â†’ SoluciÃ³n: Verifica que ticker existe (ej: 'SPY' no 'spy')

- "KeyError: 'Close'"  
  â†’ SoluciÃ³n: Script normaliza a minÃºsculas, usa 'close' no 'Close'

---

## ğŸ“ Changelog

### v1.0 (Nov 2025)
- âœ… Script data_pipeline_simple.py incluido
- ğŸ”’ 6 scripts adicionales en versiÃ³n premium

---

## âš ï¸ Disclaimer

Estos scripts son herramientas educativas. El uso de scripts NO garantiza:
- Datos 100% precisos (fuentes externas pueden tener errores)
- Ausencia de bugs (testing extensivo recomendado)
- Performance Ã³ptimo (cÃ³digo prioriza claridad sobre velocidad)

**Pero SÃ te ayuda a:**
- Automatizar tareas repetitivas
- Evitar errores comunes (validaciÃ³n incorporada)
- Acelerar desarrollo (no partir de cero)
- Aprender mejores prÃ¡cticas (cÃ³digo comentado)

**Regla de oro:**
> "Testa scripts con capital pequeÃ±o antes de usar en producciÃ³n."

---

**Parte de:** Workshop Trading AlgorÃ­tmico Aumentado con IA Generativa  
**VersiÃ³n:** 1.0 (PÃºblico)  
**Licencia:** Uso libre para participantes. No redistribuir sin permiso.
